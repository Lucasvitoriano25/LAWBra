{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32867,"status":"ok","timestamp":1709749376830,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"neYypTXiTPLr"},"outputs":[],"source":["%%capture\n","!pip install langchain\n","!pip install tiktoken"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8940,"status":"ok","timestamp":1709749385767,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"HQVdBVcZ4DW-"},"outputs":[],"source":["import json\n","\n","import numpy as np\n","import pandas as pd\n","import requests\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from tqdm import tqdm\n","from transformers import AutoTokenizer\n","\n","from langchain.text_splitter import TokenTextSplitter"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20763,"status":"ok","timestamp":1709749406517,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"bZyM6Lj5xNMe","outputId":"552ea4cb-8897-49d1-974d-35a683f905e6"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1709749709697,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"_8N9dHZyJNuL","outputId":"b0b6b916-b6de-4267-e5ae-62ddbe1c9b9d"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"markdown","metadata":{"id":"Wo9FfxbROpBo"},"source":["victor dataset links:\n","\n","https://drive.google.com/drive/folders/1Mp2f3FbND0TgVPxQrlbi780YD5fkLkEc"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1709749409768,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"2sB7em0bGKme"},"outputs":[],"source":["def extract_page_bodies_as_text_array(csv_file, text_array, chunksize = 10000):\n","  \"\"\"\n","  Extracts the \"body\" content for each page from a CSV file and returns them as a text_array,\n","  using tqdm for progress visualization.\n","\n","  Args:\n","      csv_file (str): Path to the CSV file.\n","\n","  Returns:\n","      list: A list of dictionaries, where each dictionary has the following key:\n","          - \"text\": The \"body\" content for a page.\n","  \"\"\"\n","\n","  # Read the CSV file into a DataFrame\n","\n","  df = pd.read_csv(csv_file)\n","\n","  # Use tqdm for progress bar\n","  for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting page bodies\"):\n","      # Extract document information\n","      page_body = row[\"body\"]\n","\n","      # Add page body content to the text_array\n","      text_array.append({\"text\": page_body})\n","\n","  print(extracted_bodies[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709749409768,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"-gLKDbQdMcsA"},"outputs":[],"source":["def get_docs(url, objects):\n","\n","  # Make an HTTP GET request to the URL\n","  response = requests.get(url)\n","\n","  # Check if the request was successful\n","  if response.status_code == 200:\n","      # Load each JSON object into the list\n","      for line in response.iter_lines():\n","          json_object = json.loads(line)\n","          objects.append(json_object)\n","\n","      # Now json_objects is a list of all the JSON objects in the file\n","      # For example, you can print the first JSON object\n","      print(objects[0])\n","  else:\n","      print(\"Failed to retrieve JSON data from the URL\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65655,"status":"ok","timestamp":1709749475420,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"XXMvxiJBiXkK","outputId":"3030e95d-2cb3-44a6-d1b8-ce0db630089a"},"outputs":[],"source":["# Specify the URL of the JSON file\n","acordaos_relatorio_url = \"https://dadosabertos.c3sl.ufpr.br/acordaos/json/AcordaosRelatorios.json\"\n","acordaos_votos_url = \"https://dadosabertos.c3sl.ufpr.br/acordaos/json/AcordaosVotos.json\"\n","#victor_dataset_path = to gain acess to the victor dataset you need to ask trough the link: \n","\n","# Create an empty list to store the JSON objects\n","relatorios = []\n","votos = []\n","extracted_bodies = []\n","\n","get_docs(acordaos_relatorio_url,relatorios)\n","get_docs(acordaos_votos_url,votos)\n","#extract_page_bodies_as_text_array(victor_dataset_path,extracted_bodies)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1709749475421,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"iDSrkbgNMgM-","outputId":"b0c351f5-4f4a-4171-8c07-4e2b90fabb36"},"outputs":[],"source":["text_array = [{\"text\":line[\"texto\"]} for line in relatorios + votos]\n","text_array.extend(extracted_bodies)\n","len(text_array)"]},{"cell_type":"markdown","metadata":{"id":"26r-9pp9T07b"},"source":["#### Deduplication"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1709749475421,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"1ncDCfY3T4c5"},"outputs":[],"source":["def deduplicate_exact(text_array):\n","    \"\"\"\n","    Deduplicates text by finding exact matches efficiently.\n","\n","    Args:\n","        text_array (list): A list of dictionaries, each containing a \"text\" key with the textual content.\n","\n","    Returns:\n","        list: A deduplicated list of dictionaries, removing exact duplicates.\n","    \"\"\"\n","\n","    unique_texts = []\n","    seen_texts = set()  # Use a set for efficient membership checks\n","\n","    for item in tqdm(text_array, desc=\"Deduplication in progress\"):  # Progress bar\n","        text = item[\"text\"].lower()  # Lowercase for case-insensitive comparison\n","        if text not in seen_texts:  # Check for membership in the set\n","            unique_texts.append(item)\n","            seen_texts.add(text)\n","\n","    return unique_texts"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5952,"status":"ok","timestamp":1709749481350,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"1cqzB__eYfzr","outputId":"ecc1692a-6480-4cba-9e76-8112f52a0475"},"outputs":[],"source":["text_array = deduplicate_exact(text_array)\n","len(text_array)"]},{"cell_type":"markdown","metadata":{"id":"j8GkVBAi_dsh"},"source":["#### Counting tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709749750412,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"PYzaTamE_c53"},"outputs":[],"source":["def calculate_total_tokens(dataset):\n","    # Load the tokenizer\n","\n","    total_tokens = 0\n","    for text in tqdm(dataset, desc=\"Tokenizing\"):\n","        # Tokenize the text and calculate the number of tokens\n","        tokens = tokenizer(text[\"text\"], truncation=True, padding=True)\n","        total_tokens += len(tokens[\"input_ids\"])  # Count tokens using the length of input_ids\n","\n","    return total_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":378528,"status":"ok","timestamp":1709750731512,"user":{"displayName":"Lucas Vitoriano","userId":"07079577024767584868"},"user_tz":-60},"id":"-BT8WzhuBCh5","outputId":"f8be6bf4-4afe-479d-be99-f106bf339ab0"},"outputs":[],"source":["total_tokens = calculate_total_tokens(text_array)\n","print(f\"Total number of tokens: {total_tokens}\")"]},{"cell_type":"markdown","metadata":{"id":"r7o0ZZB7Evtc"},"source":["#### Saving"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KYaCYB8lMiB2"},"outputs":[],"source":["json_file_path = \"/content/drive/MyDrive/Projetos/deepL/data/law_dataset_raw.json\"\n","\n","\n","# Save the array to the JSON file\n","with open(json_file_path, \"w\") as json_file:\n","    json.dump(text_array, json_file)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
